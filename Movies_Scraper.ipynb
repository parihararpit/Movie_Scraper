{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movies_Scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ncxL2OxcStP",
        "colab_type": "text"
      },
      "source": [
        "***Review Link Scraping***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIzgxxWcPX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen as uReq\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "############################################################\n",
        "\n",
        "# online\n",
        "# Movies of five consecutive years from 2020-2016\n",
        "movies_link = [\"https://www.imdb.com/list/ls071285764/\",\"https://www.imdb.com/list/ls071285512/\",\"https://www.imdb.com/list/ls058813655/\",\"https://www.imdb.com/list/ls062476111/\",\"https://www.imdb.com/list/ls058938704/\"]\n",
        "\n",
        "cur_dir = '/content/drive/My Drive/ArtificialIntelligence_project'\n",
        "out_file = open( cur_dir + '/dataset/movies.csv', 'w', newline='')\n",
        "\n",
        "\n",
        "#write index\n",
        "words  = ['title', 'reviews_link']\n",
        "writer = csv.writer(out_file)\n",
        "writer.writerow(words)\n",
        "out_file.close()\n",
        "\n",
        "for movies in movies_link:\n",
        "  u_client = uReq(movies) # open url in code/memory html\n",
        "  html_file = u_client.read()\n",
        "  u_client.close() # not needed anymore\n",
        "\n",
        "  # list of all movies titles\n",
        "  bsoup = soup(html_file, \"html.parser\") \n",
        "  lst = bsoup.findAll(\"h3\", {\"class\": \"lister-item-header\"})\n",
        "\n",
        "  cur_dir = '/content/drive/My Drive/ArtificialIntelligence_project'\n",
        "  out_file = open( cur_dir + '/dataset/movies.csv', 'a', newline='')\n",
        "\n",
        "\n",
        "  for item in lst:\n",
        "      title_tag = item.find(\"a\", href = True)\n",
        "      title = title_tag.text.strip()\n",
        "      link = 'https://www.imdb.com' + title_tag['href'].split('?')[0] + 'reviews?ref_=tt_urv'\n",
        "      if not title or not link:\n",
        "          continue\n",
        "      \n",
        "      words  = [title, link]\n",
        "      writer = csv.writer(out_file)\n",
        "      writer.writerow(words)\n",
        "  out_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71zqdn3IchCO",
        "colab_type": "text"
      },
      "source": [
        "***This Code is used to simulate Browser***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUnxiwygcoUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install curl software-properties-common # read about curl\n",
        "!curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -\n",
        "!sudo apt-get install nodejs # read nodejs and npm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YYcDrhOdE9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!npm -v\n",
        "!node -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DexI-w0vdvAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install chromium, its driver, and selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver #read about\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium #read about"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1nEIxpIeAgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read how does this works\n",
        "from selenium import webdriver\n",
        "def save_screenshot(driver: webdriver.Chrome, path: str = '/content/dataset/screenshot.png'):\n",
        "    # Ref: https://stackoverflow.com/a/52572919/\n",
        "    original_size = driver.get_window_size() # what does it do ?\n",
        "    required_width = driver.execute_script('return document.body.parentNode.scrollWidth')\n",
        "    required_height = driver.execute_script('return document.body.parentNode.scrollHeight')\n",
        "    driver.set_window_size(required_width, required_height)\n",
        "    # driver.save_screenshot(path)  # has scrollbar\n",
        "    driver.find_element_by_tag_name('body').screenshot(path)  # avoids scrollbar\n",
        "    driver.set_window_size(original_size['width'], original_size['height'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEPI1Iw6eak9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "Testing code for a movie's review\n",
        "\n",
        "Redundant code\n",
        "'''\n",
        "\n",
        "import time\n",
        "from selenium import webdriver\n",
        "\n",
        "# prepare the option for the chrome driver\n",
        "# options = webdriver.ChromeOptions()\n",
        "# options.add_argument('headless')\n",
        "\n",
        "# browser = webdriver.Chrome(chrome_path)\n",
        "\n",
        "# set options to be headless, ..\n",
        "\n",
        "# what is ECMA ?\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless') # why headless\n",
        "options.add_argument('--no-sandbox') # why ?\n",
        "options.add_argument('--disable-dev-shm-usage') # why ?\n",
        "\n",
        "# open it, go to a website, and get results\n",
        "chrome = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "# search_box = chrome.find_elements_by_xpath(\"//input[@name='q' and @type='text' ]\")[0]\n",
        "# search_box.send_keys(\"print('Hello World')\")\n",
        "chrome.get('https://www.imdb.com/title/tt4500922/reviews?ref_=tt_sa_3')\n",
        "\n",
        "load_button = chrome.find_elements_by_xpath(\"//*[@id='load-more-trigger']\")[0]\n",
        "load_button.click()\n",
        "time.sleep(2)\n",
        "load_button.click()\n",
        "time.sleep(2)\n",
        "\n",
        "save_screenshot(chrome)\n",
        "print(chrome.page_source)  # results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5vHDIMGejMT",
        "colab_type": "text"
      },
      "source": [
        "Now we have installed all necessary modules needed for simulation of a browser in program.\n",
        "\n",
        "The need for comes in picture because static html page of a movie's review page have only 25 reviews, and it has a button 'Load More' to load more reviews on that page.\n",
        "\n",
        "To load more reviews on the page, we need to click that button, that's why we need to simulate browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSNqofMUeqUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "from urllib.request import urlopen as uReq\n",
        "\n",
        "# read BeautifulSoup https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import csv\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69QXjvXze1Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "cur_dir='/content/drive/My Drive/ArtificialIntelligence_project'\n",
        "out_file = open( cur_dir + '/dataset/reviews.csv', 'w', newline='', encoding=\"utf-8\")\n",
        "k = 1\n",
        "\n",
        "head  = ['imdb_link', 'review_title', 'review_text', 'rating']\n",
        "writer = csv.writer(out_file) # read about csv module in python https://www.geeksforgeeks.org/working-csv-files-python/\n",
        "writer.writerow(head)\n",
        "\n",
        "data_path = cur_dir + '/dataset/movies.csv'\n",
        "movies_list = open(data_path).read().split('\\n')\n",
        "movies_list=[]\n",
        "with open(data_path,'r') as rf:\n",
        "  reader = csv.reader(rf, delimiter=',')\n",
        "  for row in reader:\n",
        "    movies_list.append(row[1])\n",
        "############## prepare browser simulation #############################\n",
        "\n",
        "# prepare the option for the chrome driver\n",
        "# options = webdriver.ChromeOptions()\n",
        "# options.add_argument('headless')\n",
        "\n",
        "# browser = webdriver.Chrome(chrome_path)\n",
        "\n",
        "# set options to be headless, ..\n",
        "\n",
        "# read about ChromeOptions https://chromedriver.chromium.org/capabilities\n",
        "options = webdriver.ChromeOptions() \n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# open it, go to a website, and get results\n",
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "# use we.get(url) to get a web page with js in wd\n",
        "############## browser is in wd #############################\n",
        "\n",
        "# ignore first row, as it has header only\n",
        "for movie in movies_list[1:len(movies_list)-1]:\n",
        "    reviews_link=movie\n",
        "    print(reviews_link + \"\\n\")\n",
        "\n",
        "    wd.get(reviews_link)\n",
        "\n",
        "    try:\n",
        "        load_button = wd.find_elements_by_xpath(\"//*[@id='load-more-trigger']\")[0]\n",
        "        for i in range(2):\n",
        "            load_button.click()\n",
        "            time.sleep(3)\n",
        "    except:\n",
        "        print('Load Button Not Found!!')\n",
        "        continue\n",
        "\n",
        "    html_file = wd.page_source\n",
        "\n",
        "    bsoup = soup(html_file, \"html.parser\")\n",
        "    #bsoup = bsoup.encode(\"utf-8\")\n",
        "    lst = bsoup.findAll(\"div\", {\"class\": \"lister-item-content\"})\n",
        "\n",
        "    for item in lst:\n",
        "\n",
        "        title_tag = item.find(\"a\", {\"class\": \"title\"})\n",
        "        rating_tag = item.find(\"span\", {\"class\": \"rating-other-user-rating\"})\n",
        "        review_tag = item.find('div', {'class': 'text show-more__control'})\n",
        "\n",
        "        # if any field is not available ignore this review\n",
        "        if not rating_tag or not review_tag or not title_tag:\n",
        "            continue\n",
        "\n",
        "        imdb_link = reviews_link\n",
        "        review_title = title_tag.text.strip()\n",
        "        review_text = review_tag.text.strip()\n",
        "        rating = rating_tag.findChildren('span')[0].text.strip()\n",
        "\n",
        "        # verify output\n",
        "        print(\"\\n\\nReview page: \" + imdb_link\n",
        "            + \"\\nReview title: \" + review_title\n",
        "            + \"\\nReview text: \" + review_text\n",
        "            + \"\\nRating: \" + rating)\n",
        "        # break\n",
        "\n",
        "\n",
        "        words = [imdb_link, review_title, review_text, rating]\n",
        "        writer = csv.writer(out_file)\n",
        "        writer.writerow(words)\n",
        "        \n",
        "        # break\n",
        "        \n",
        "    # waiting for few seconds, so that imdb does not \n",
        "    # recognise our system as bot and does not block our ip\n",
        "    time.sleep(3)\n",
        "    # break\n",
        "    \n",
        "        \n",
        "out_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P4LQp7iBlX-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Finally store our data (review_title, review_text, rating) in dataset.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYErw7Tae5qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import csv\n",
        "\n",
        "\n",
        "cur_dir = '/content/drive/My Drive/ArtificialIntelligence_project'\n",
        "\n",
        "reviews_data = open(cur_dir + '/dataset/reviews.csv', 'r', newline='', encoding=\"utf-8\")\n",
        "dataset = open(cur_dir + '/dataset/datasets.csv', 'w', newline='', encoding=\"utf-8\")\n",
        "\n",
        "reviews_writer = csv.writer(dataset)\n",
        "reviews_reader = csv.reader(reviews_data, delimiter=',')\n",
        "\n",
        "# write index\n",
        "words  = ['review_title', 'review', 'rating']\n",
        "reviews_writer.writerow(words)\n",
        "\n",
        "# print(\"Dataset:\")\n",
        "k = 1\n",
        "\n",
        "for line in reviews_reader:\n",
        "    if k==1:\n",
        "        k = k+1\n",
        "        continue\n",
        "    words = review_title, review_text, rating = line[1:4]\n",
        "    reviews_writer.writerow(words)\n",
        "\n",
        "    # print first 10 reviews, for verification\n",
        "    # if k<10:\n",
        "    #     print(\"\\n\\nReview title: \" + review_title\n",
        "    #           + \"\\nReview text: \" + review_text\n",
        "    #           + \"\\nRating: \" + rating)\n",
        "    # k=k+1\n",
        "\n",
        "reviews_data.close()\n",
        "dataset.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}